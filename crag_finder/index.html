<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="">
    <meta name="author" content="Michael Skaug">

    <title>Michael Skaug</title>

    <!-- Bootstrap core CSS -->
    <link href="../bootstrap_dist/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="../bootstrap_dist/css/jumbotron-narrow.css" rel="stylesheet">

    <link href="../site.css" rel="stylesheet">

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    
      ga('create', 'UA-36183871-2', 'auto');
      ga('send', 'pageview');
    
    </script>    
  </head>

  <body>

    <div class="container">
        <a href="../"><span class="h5 text-muted">MichaelSkaug </span></a> <span class="date">September 1, 2018</span>
        
        <h1>Finding climbing locations with a ConvNet and web map tiles</h1>
        <p>Deep convolutional neural networks have become the stardard approach in many computer vision applications, yet they're still difficult to use in fields, like geospatial, where images are not 256x256 pixel RGB jpegs. In other words, places where <a href="https://cloud.google.com/vision/">Google Vision API</a> isn't going to be much help. To make matters worse, geospatial data has traditionally been stored in large cumbersome files and required significant pre-processing to get it ready for analysis.</p>  
        
        <h3>Machine learning friendly geospatial data</h3>
        <p>Fortunately, it's getting easier to use big geospatial data. There's momentum behind the <a href="http://www.cogeo.org/">COG</a> file format, which enables more friendly data access and awesome APIs like <a href="https://github.com/radiantearth/tiles.rdnt.io">tiles.rdnt.io</a>. And although they're designed more for display than analytic purposes, web map tiles are an easy to consume geospatial data set with world-wide coverage. I first started thinking about using map tiles for analysis when <a href="https://mapzen.com/">Mapzen</a> created terrain tiles, which are map tiles where the color encodes elevation, kind of like a <a href="https://en.wikipedia.org/wiki/Digital_elevation_model">DEM</a>.</p>

        <p>With map tiles serving as a convenient data set and a deep ConvNet as a general purpose computer vision tool, I just needed a problem to solve! How about finding climbing locations! The locations of many climbing areas are already known of course, but climbers are always on the lookout for new crags and a common tool in that quest is Google Maps, so there was reason to believe that I could train a model to use similar map data to find climbing areas.</p>

        <h3>The labels</h3>
        <p>The basic idea was to train a ConvNet to do binary classification of map tiles, identifying which ones contain climbing and which ones don't. To start building a data set for training and testing, I used a list of more than 1000 climbing areas from <a href="https://www.mountainproject.com/">MountainProject.com</a>. That provided examples of locations with climbing, but to do binary classifaction I also needed examples of locations without climbing. Here I made the assumption that climbing locations are relatively rare, so if I randomly picked locations in the United States I could assume they did not contain climbing.</p>

        <p><img class="fullcol" src="locations_map-80.jpg"></p>

        <h3>The map tiles</h3>
        <p>The next step was to gather the map tiles corresponding to each example. Web map tiles have a url which follows a standard pattern: <span class="code">{base-url}/{zoom}/{X}/{Y}.jpg</span> and with a longitude, latitude and zoom level, it's straight forward to calculate the <span class="code">{X}</span> and <span class="code">{Y}</span> values for the corresponding tile. What's nice about map tiles for deep learning is that every tile is the same size, 256x256, and getting different types of data is as simple as changing the <span class="code">{base_url}</span>. </p>
        
        <p>For this task, it made sense to use satellite imagery, since rocks look different than trees, for example. But in satellite imagery, a flat rock slab (no climbing) looks similar to a steep rock wall (climbing). So I also included terrain tiles, which encode topographic elevation in the RGB colors of the image. With satellite imagery and terrain, I was hopeful that a model could indentify steep rocky areas where there is likely to be climbing. But I was worried that it would identify all mountainous regions as having climbing, which is true in some ways, but there's another important factor which determines which areas are actually explored by climbers, and that's accessibility, or distance from roads or towns. To provide the model with some information about accessibility, I also included a simple, high-contrast map tile which mainly depicts roads. These "street" map tiles were available in the usual RGB jpeg format, but since they were basically monochrome, I converted them to a single grayscale layer, rather than keep all three, redundant RGB layers.</p>

        <p><img class="fullcol" src="input_data@2x-80.jpg"></p>

        <h3>The network</h3>
        <p>With the labels and map tiles in hand, I was ready to train a ConvNet. In situations like this where the training data set is relatively small, it's common to employ transfer learning, where you "fine-tune" a model that has been pre-trained on a much larger data set. But those pre-trained models are usually limited to small 3-channel RGB images and it's unclear to me how to extend them to work with N-channel images, so I trained a small ConvNet from scratch. I used the typical strategies, like dropout and regularization, to prevent overfitting and image rotation and flips to augment the training examples. I performed the training using <a href="https://keras.io/">Keras</a> on a GPU EC2 instance on AWS. (The <a href="https://aws.amazon.com/machine-learning/amis/">deep learning AMIs</a> were very convenient.)</p>

        <p><img class="fullcol" src="network.jpg"></p>

        <h3>The results</h3>
        <h4>You're only as good as you're training data</h4>
        <p>I was pleasantly surprised that the model achieved 84% accuracy on the test set. Using a threshold of <span class="code">p = 0.5</span> on the output probabilities to distinguish climbing from no-climbing areas, the number of false positives and false negatives were about the same.</p>

        <p><img class="three-quarter-col" src="test_results_confusion_matrix.png"></p>

        <p>And when plotting the results on a map, there were no obvious patterns in the location of the correct and incorrect predictions.</p>

        <p><img class="fullcol" src="test_results_map.jpg"></p>

        <p>One of the best parts about using web map tiles is that becuase of their world-wide coverage, the model can be used to run predictions for any location on earth. That isn't to say that the predictions will neccessarily be <span class="italic">accurate</span>. Rather than run inference on discrete locations like those in the test set, I selected a grid of locations covering Santa Fe, New Mexico to see what the model would do. The result was not encouraging. Shown below is a heatmap of the probability of climbing around Santa Fe.</p>

        <p><img class="fullcol" src="SantaFe_predictions.jpg"></p>

        <p>There are a couple of things going on. The small squares are the same size and location of the satellite and terrain map tiles used in the model. You also see larger square regions where the predictions are correlated. These are the size and locations of the "streets" map tiles used in the model. So apparently the "street" map tiles are having a strong influence on the predictions. We also see a large area of high probablity over downtown Santa Fe, which is incorrect. The model is seems to be predicting that either mountainous areas or areas of high road density are correlated with climbing. This points to a problem in the training data and how the "no-climbing" examples were chosen. The "climbing" examples contained some locations near or in cities with high road density, but by picking random locations in the US as "no-climbing" examples, it's very unlikely that they include any high density road areas. The result is that the model learned that high road density = climbing.</p>

        <h3>Next steps</h3>
        <p>Deep learning models often fail due to problems with training data and this case was no different. The next step in improving this model would be to ensure that both classes contained geographically diverse examples, in particular that the "no-climbing" class contained rural and urban examples.</p>

        <p>But, I'm not sure it's worth expending more effort on this particular model - it's only meant to predict climbing locations after all. What I'm most excited about is the general approach of using deep ConvNets on map tiles to find objects and classify the earth's surface. All that's need is a list of labelled locations or polygons and map tiles.</p>

      <footer class="footer">
        <p>&copy; Michael Skaug 2018</p>
      </footer>

    </div> <!-- /container -->

    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <script src="../bootstrap_dist/js/ie10-viewport-bug-workaround.js"></script>
  </body>
</html>
