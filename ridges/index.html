<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="">
    <meta name="author" content="Michael Skaug">

    <title>Michael Skaug</title>

    <!-- Bootstrap core CSS -->
    <link href="../bootstrap_dist/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="../bootstrap_dist/css/jumbotron-narrow.css" rel="stylesheet">

    <link href="../site.css" rel="stylesheet">

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    
      ga('create', 'UA-36183871-2', 'auto');
      ga('send', 'pageview');
    
    </script>    
  </head>

  <body>

    <div class="container">
        <a href="../"><span class="h5 text-muted">MichaelSkaug </span></a> <span class="date">July 19, 2020</span>
        
        <h1>Identifying ridges in topography</h1>
        <p>Years ago I tried to use what I knew about image processing to identify ridges in a digital elevation model. I quickly realized that the way I intuitively identify a ridge is not easy to describe algorithmically. I knew it had something to do with the slope and curvature of the landscape, but I never came up with an algorithm that could reproduce the ridge lines I would <a href="https://twitter.com/mike_skaug/status/1001649480255488000">intuitively identify</a>. The two main problems are that my idea of a "ridge" is context dependent - it has to be more "ridge like" than the surrounding terrain - and I naturally connect ridge lines into simple and continuous features even if there are breaks.</p>

        <p>The problem remained in the back of my mind until I learned more about deep learning and I started experimenting with <a href="../crag_finder/">map tiles</a> and <a href="../projects/TerrainShade/">terrain tiles</a>. Deep learning seemed like it could be effective on this problem because it might be able model the multi-scale and context dependent clues my own perception uses to identify ridges. I also knew that digital terrain data was available as deep learning friendly map tiles from <a href="https://registry.opendata.aws/terrain-tiles/">AWS/Mapzen</a>. So the basic idea was to train a deep learning model to do image segmentation to identify ridges in terrain tiles. I anticipated a few challenges. Ridges are thin, one pixel wide features, which is quite different than the blobs of pixels typically classified by image segmentation models. So I didn't know if standard architectures would work. The big problem though was the absence of training data. This was supposed to be a fun project, so I wasn't about to sit down and manually annotate 1000s of images for a training data set. Maybe I could use my crude, semi-functional image processing algorithm to label the data for me?</p>
        
        <h3>Weak supervision</h3>
        <p>Lacking sufficient (or any) training data, I looked for alternative approaches and one that I think has a lot of potential generally is <a href="http://ai.stanford.edu/blog/weak-supervision/">weak supervision</a>. Weak supervision is a category of methods that try to make use of low quality labels by, for example, training a generative model over a group of noisy labeling functions or by pretraining on the low quality labels and fine tuning on a small number of high quality labels. (Which is what I did.)</p>

        <p><img class="fullcol" src="ratner_blog_diagram.jpg"><a class="smaller indent" href="http://ai.stanford.edu/blog/weak-supervision/">[Weak Supervision: A New Programming Paradigm for Machine Learning]</a></p>

        <p>In my case, the low quality labeled data could be generated using my hand-crafted, mediocre image processing function for finding ridges, which I creatively named <a class="code" href="https://github.com/mikeskaug/ridges/blob/ccd46e3aa496c48cba00e2910a11b2253f4206f4/src/transforms.py#L77">ridges()</a>. After collecting all of the zoom 12 terrain tiles covering Colorado (~4000), I used the hand-crafted function to generate binary masks representing ridge/not-ridge pixels, which would serve as targets for training an image segmentation model.</p>

        <h3>Thin feature segmentation</h3>
        <p>Then began my unnecessarily complicated quest to find a model that would identify ridge pixels. I tried several different network architectures, including a U-Net, <a href="https://arxiv.org/abs/1709.00179">local feature extractor</a> and some bespoke creations, different loss functions and different pre-processing. (The <a href="https://github.com/mikeskaug/ridges">repo</a> bears witness to these abandoned paths.) It would turn out that much of this exploration was unnecessary, but there were three factors that guided my search:</p>
        
        <p class="indent">&bullet; Large class imbalance. Even in very "ridgey" terrain, only about 10% of the pixels should be classified as ridge.</p>
        <p class="indent">&bullet; Very thin features. Unlike most applications of image segmentation, the features are not blobs of pixels, but long, 1-pixel wide features.</p>
        <p class="indent">&bullet; It can't be that hard. I hand-crafted a function that did <span class="italic">okay</span> at identifying ridges, and it even used convolutions, so I knew a deep convolutional network should work. This is why I couldn't give it up, even when my initial experiments didn't learn anything.</p>

        <p>After all the experiments, the key to making it work was properly scaling the input :( The mistake which prevented me from catching the bug earlier was using a custom image loader while doing local testing and debugging which correctly interpreted the geotiff pixel values as floating point numbers, while Keras' <span class="code">ImageDataGenerator</span> assumes 8-bit integers. So while testing locally, the input looked fine, but while training on AWS, the model was getting blank images filled with <span class="code">255</span>!</p>

        <p>The architecture I ended up using was the HED, or <a href="https://arxiv.org/abs/1504.06375">holistically-nested edge detection</a>, model initialized with weights from the VGG16 model. I decided to try HED because it was developed for edge detection, which is a similar problem in that it's subject to large class imbalance and must extract thin features. The architecture is basically a stack of convolutional blocks similar to the encoder side of a U-Net, but then instead of a decoder branch with transposed convolutions to return to the original size, it uses regular upsampling. It's also a multi-output model and it uses the output of each convolutional block to provide supervision. I didn't try outputting only the last layer, but the multi-output supervision is an interesting sort of regularization that helps in training.</p>

        <p><img class="centered" style="width:75%;" src="HED_architecture.jpg"></p>

        <h3>Fine tuning</h3>
        <p>The trained model performed well in terms of accuracy and <a href="https://en.wikipedia.org/wiki/Jaccard_index">intersection over union (IOU)</a> against the test set, so I knew that it wasn't overfitting. But there was a problem. The test set was also generated by the heuristic algorithm and the point of this project was to develop a model that was better than the heuristic! So in the end I still needed some hand-labeled examples, but with a very small number of high quality labels, like only 10!, I could fine-tune the network and evaluate the heuristic and the HED model.</p>

        <p><img class="centered fullcol" src="example_output.jpg"><p class="smaller indent">Example inputs and the corresponding manually created target masks, heuristic outputs and outputs from the weakly supervised HED model and the model fine-tuned on hand-labeled examples. Below each output is the mean IOU evaluated against the holdout set.</p></p>

        <h3>Conclusion</h3>
        <p>There were many starts and stops to this project (just see the Github history!), so I was happy to finally see that it could work to use a deep learning model to identify ridges. I wouldn't say it works wildly better than the hand-crafted heuristic, but it is better and I learned a lot along the way. This was my first experience using weak supervision, which I think could be a powerful approach in most domains where lots of high quality labeled data is expensive or nonexistent. I also experimented with some new architectures, loss functions and even a custom kernel initializer! As usual, there's much more that could be done, like a loss function that enhances the connectedness of the predicted ridges, but given how long it took to get this far, I don't know if I'll get to it.</p>

        <p>One thing that kept me going was imagining being able to run the inference on a large swath of terrain and explore ridges! Here are some examples from across the American west:</p>

        <p><img class="centered fullcol" src="example_predictions.jpg"></p>
        <p></p>
      <footer class="footer">
        <p>&copy; Michael Skaug </p>
      </footer>

    </div> <!-- /container -->

    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <script src="../bootstrap_dist/js/ie10-viewport-bug-workaround.js"></script>
  </body>
</html>
